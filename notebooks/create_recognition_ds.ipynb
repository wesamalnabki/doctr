{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset \n",
    "from pdf2image import convert_from_bytes\n",
    "from PIL import ImageDraw\n",
    "import uuid \n",
    "import os \n",
    "import json \n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "VAL_SIZE = 0.02\n",
    "MAX_PAGES_COUNT =  100_000 # None to ignore \n",
    "\n",
    "recognition_root_images = r\"/opt/walnabki/OCR_Dataset/recognition_ds/images\"\n",
    "os.makedirs(recognition_root_images, exist_ok=True)\n",
    "recognition_root_labels = r\"/opt/walnabki/OCR_Dataset/recognition_ds/labels\"\n",
    "os.makedirs(recognition_root_labels, exist_ok=True)\n",
    "\n",
    "\n",
    "recognition_train_root_images = r\"/opt/walnabki/OCR_Dataset/recognition_train/images\"\n",
    "os.makedirs(recognition_train_root_images, exist_ok=True)\n",
    "recognition_train_root_labels = r\"/opt/walnabki/OCR_Dataset/recognition_train/labels\"\n",
    "os.makedirs(recognition_train_root_labels, exist_ok=True)\n",
    "\n",
    "train_json_path = r'/opt/walnabki/OCR_Dataset/recognition_train/labels.json'\n",
    "\n",
    "recognition_val_root_images = r\"/opt/walnabki/OCR_Dataset/recognition_val/images\"\n",
    "os.makedirs(recognition_val_root_images, exist_ok=True)\n",
    "recognition_val_root_labels = r\"/opt/walnabki/OCR_Dataset/recognition_val/labels\"\n",
    "os.makedirs(recognition_val_root_labels, exist_ok=True)\n",
    "\n",
    "val_json_path = r'/opt/walnabki/OCR_Dataset/recognition_val/labels.json'\n",
    "\n",
    "dataset = load_dataset('pixparse/pdfa-eng-wds', streaming=True )\n",
    "\n",
    "\n",
    "def adjust_bbox(word_bbox, img):\n",
    "    \n",
    "    xr = word_bbox[0]*img.size[0]\n",
    "    yr = word_bbox[1]*img.size[1] \n",
    "    w = word_bbox[2]*img.size[0]\n",
    "    h = word_bbox[3]*img.size[1]\n",
    "    xl = xr + w \n",
    "    yl = yr + h\n",
    "    return [xr,yr, xl, yl]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_PAGES_COUNT =  10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ds \n",
    "ctr = 0\n",
    "for sample in iter(dataset['train']):\n",
    "        \n",
    "    if MAX_PAGES_COUNT and ctr > MAX_PAGES_COUNT:\n",
    "        break\n",
    "\n",
    "    pdf = sample['pdf']\n",
    "    pages  =sample['json']['pages']\n",
    "    pages_imgs = convert_from_bytes(pdf)\n",
    "\n",
    "    for page_id in range(len(pages_imgs)): \n",
    "        \n",
    "        ctr +=1\n",
    "        words = pages[page_id]['words']['text']\n",
    "        bboxs = pages[page_id]['words']['bbox']\n",
    "        page_img = pages_imgs[page_id]\n",
    "\n",
    "        for word, bbox in zip(words, bboxs):\n",
    "            fn = str(uuid.uuid4()) \n",
    "            page_labels_dict = dict()\n",
    "            try:\n",
    "                bbox_adj = adjust_bbox(word_bbox=bbox, img = page_img)\n",
    "                cropped_img = page_img.crop(bbox_adj)\n",
    "                cropped_img.save(os.path.join(recognition_root_images, fn + \".png\"))\n",
    "                page_labels_dict[fn+ \".png\"] = word\n",
    "                with open(os.path.join(recognition_root_labels, fn + \".json\"), 'w') as outfile:\n",
    "                    json.dump(page_labels_dict, outfile, indent=2)\n",
    "            except:\n",
    "                print(f\"escape word --> {word}\")\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split the dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3083, 63)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Split the dataset\")\n",
    "img_names = [x[:-4] for x in os.listdir(recognition_root_images)]\n",
    "x_train ,x_test = train_test_split(img_names,test_size=VAL_SIZE, random_state=42) \n",
    "len(x_train), len(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving imgs to val folder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:00<00:00, 20315.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating labels file for training\n",
      "Moving imgs to training folder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3083/3083 [00:00<00:00, 21591.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating labels file for training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Moving imgs to val folder\")\n",
    "for fn_test in tqdm(x_test):\n",
    "    src_lab = os.path.join(recognition_root_labels, fn_test + \".json\") \n",
    "    des_lab = os.path.join(recognition_val_root_labels, fn_test + \".json\") \n",
    "\n",
    "    src_img = os.path.join(recognition_root_images, fn_test + \".png\") \n",
    "    des_img = os.path.join(recognition_val_root_images, fn_test + \".png\")\n",
    "\n",
    "    shutil.move(src_lab, des_lab) \n",
    "    shutil.move(src_img, des_img)\n",
    "\n",
    "print(\"Creating labels file for training\")\n",
    "all_data_val = dict()\n",
    "for f in os.listdir(recognition_val_root_labels):\n",
    "    with open(os.path.join(recognition_val_root_labels , f)) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        all_data_val.update(data) \n",
    "\n",
    "\n",
    "with open(val_json_path, 'w') as outfile:\n",
    "    json.dump(all_data_val, outfile, indent=2)\n",
    "\n",
    "\n",
    "print(\"Moving imgs to training folder\")\n",
    "for fn_train in tqdm(x_train):\n",
    "    src_lab = os.path.join(recognition_root_labels, fn_train + \".json\") \n",
    "    des_lab = os.path.join(recognition_train_root_labels, fn_train + \".json\") \n",
    "\n",
    "    src_img = os.path.join(recognition_root_images, fn_train + \".png\") \n",
    "    des_img = os.path.join(recognition_train_root_images, fn_train + \".png\")\n",
    "\n",
    "    shutil.move(src_lab, des_lab) \n",
    "    shutil.move(src_img, des_img)\n",
    "\n",
    "print(\"Creating labels file for training\")\n",
    "all_data_train = dict()\n",
    "for f in os.listdir(recognition_train_root_labels):\n",
    "    with open(os.path.join(recognition_train_root_labels , f)) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        all_data_train.update(data) \n",
    "\n",
    "\n",
    "with open(train_json_path, 'w') as outfile:\n",
    "    json.dump(all_data_train, outfile, indent=2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
